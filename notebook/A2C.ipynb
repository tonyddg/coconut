{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2C\n",
    "## 实现代码\n",
    "* 多步 TD 目标\n",
    "    * 使用 Python 列表管理前 1 - m 步的 Transition\n",
    "    * 每次插入新的 Transition 后, 更新 Transition 的回报 (乘上 $\\gamma^{\\Delta t}$)\n",
    "    * 当 Episode 结束或累计 m 步 Transition, 打包为一个 Batch 进行训练\n",
    "    * 打包时注意 Batch 中每个 Transition 的 next_state 相同, 但计算 TD 目标时 $\\gamma$ 的指数不同\n",
    "    * 使用多步 TD 目标时, 模型反向传播次数减少, 大幅提高了训练速度, 但又能使训练更加稳定 \n",
    "* 使用 `torch.distributions.Categorical()` 根据概率质量分布采样\n",
    "* 使用 `torch.Tensor.detach()` 将张量转变为没有梯度的常量, 用于计算策略梯度\n",
    "\n",
    "## 特点记录\n",
    "* 相比于 DQN, 由于无法使用经验回放, 可以发现 A2C 的稳定性非常差, 即使是通过 Optuna 等工具寻找最优超参数, 其在收敛后的表现依然差于 DQN, 但同时 A2C 的训练速度相比 DQN 稍快 \n",
    "* 通过引入多步 TD 目标, 可以很好地改善 A2C 不稳定的问题, 但依然存在; 此外由于多步 TD 目标中 m 步经验被打包为一个 Batch, 反向传播次数减少, 训练速度进一步加快, 相比 DQN, 达到收敛所需的 Episode 增大一倍但收敛训练时间缩短一倍, 能大量搜索超参数\n",
    "* A2C 还有特点是, 如果训练停止时模型虽然收敛但出现训练恶化, 则实际测试时模型表现也将非常差\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from ipynb_utility import get_file, set_seed\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(get_file()), '..')))\n",
    "\n",
    "seed = 114514\n",
    "set_seed(seed)\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from src.RL.A2C import A2C, A2C_WithMultiStep, HyperParam\n",
    "from src.RL.utility.train_rl import RL_Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\playground\\Lib\\site-packages\\gymnasium\\wrappers\\rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at d:\\code\\python\\coconut\\notebook\\train_vedio\\CartPole-v1_A2C folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "100%|██████████| 800/800 [10:08<00:00,  1.31it/s]\n",
      "d:\\miniconda3\\envs\\playground\\Lib\\site-packages\\gymnasium\\wrappers\\rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at d:\\code\\python\\coconut\\notebook\\test_vedio\\CartPole-v1_A2C folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CartPole-v1_A2C:  500.0\n"
     ]
    }
   ],
   "source": [
    "model = A2C(HyperParam(\n",
    "    lr_critic = 1.6e-3,\n",
    "    lr_actor = 7.5e-5,\n",
    "    gamma = 0.99,\n",
    "    hidden_dim = 128\n",
    "))\n",
    "\n",
    "teacher = RL_Teacher(model, \"CartPole-v1_A2C\", f\"seed_{seed}\", id = \"CartPole-v1\", render_mode = \"rgb_array\")\n",
    "teacher.train(episode = 800, is_fix_seed = True)\n",
    "print(\"CartPole-v1_A2C: \", teacher.test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\playground\\Lib\\site-packages\\gymnasium\\wrappers\\rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at d:\\code\\python\\coconut\\notebook\\train_vedio\\CartPole-v1_A2C_WithMultiStep folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "100%|██████████| 1200/1200 [11:40<00:00,  1.71it/s]\n",
      "d:\\miniconda3\\envs\\playground\\Lib\\site-packages\\gymnasium\\wrappers\\rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at d:\\code\\python\\coconut\\notebook\\test_vedio\\CartPole-v1_A2C_WithMultiStep folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "100%|██████████| 10/10 [00:16<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CartPole-v1_A2C_WithMultiStep:  500.0\n"
     ]
    }
   ],
   "source": [
    "model = A2C_WithMultiStep(HyperParam(\n",
    "    lr_critic = 2.2e-3,\n",
    "    lr_actor = 1.2e-4,\n",
    "    m = 5\n",
    "))\n",
    "\n",
    "teacher = RL_Teacher(model, \"CartPole-v1_A2C_WithMultiStep\", f\"seed_{seed}\", id = \"CartPole-v1\", render_mode = \"rgb_array\")\n",
    "teacher.train(episode = 1200, is_fix_seed = True)\n",
    "print(\"CartPole-v1_A2C_WithMultiStep: \", teacher.test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2C With m-step td target 的 Optuna 超参数搜索\n",
    "\n",
    "# import logging\n",
    "# import sys\n",
    "\n",
    "# import optuna\n",
    "\n",
    "# # Add stream handler of stdout to show the messages\n",
    "# optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# def target(trial: optuna.Trial):\n",
    "#     lr_critic = trial.suggest_float(\"lr_critic\", 5e-3, 5e-3, log = True)\n",
    "#     lr_actor = trial.suggest_float(\"lr_actor\", 5e-3, 5e-3, log = True)\n",
    "\n",
    "#     model = A2C_WithMultiStep(HyperParam(\n",
    "#         lr_critic = lr_critic,\n",
    "#         lr_actor = lr_actor,\n",
    "#         gamma = 0.99,\n",
    "#         hidden_dim = 128\n",
    "#     ))\n",
    "\n",
    "#     teacher = RL_Teacher(model, \"CartPole-v1_A2C_WithMultiStep_param_search\", f\"lrc_{lr_critic:.2e}_lra_{lr_actor:.2e}\", id = \"CartPole-v1\", render_mode = \"rgb_array\")\n",
    "#     avg_return = teacher.train(\n",
    "#         episode = 1200, is_log = False, \n",
    "#         last_episode_return = 300, \n",
    "#         is_fix_seed = True\n",
    "#     )\n",
    "#     return teacher.test(\n",
    "#         is_log_vedio = True, \n",
    "#         vedio_record_gap = 6\n",
    "#     ) + avg_return * 0.1\n",
    "\n",
    "# study = optuna.create_study(\n",
    "#     direction = \"maximize\", \n",
    "#     study_name = f\"CartPole-v1_A2C_WithMultiStep\", \n",
    "#     storage = \"sqlite:///optuna_study/CartPole-v1_A2C_WithMultiStep.db\", \n",
    "#     load_if_exists = True\n",
    "# )\n",
    "# study.optimize(target, 10)\n",
    "# print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2C 的 Optuna 超参数搜索\n",
    "\n",
    "# import logging\n",
    "# import sys\n",
    "\n",
    "# import optuna\n",
    "\n",
    "# # Add stream handler of stdout to show the messages\n",
    "# optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# def target(trial: optuna.Trial):\n",
    "#     lr_critic = trial.suggest_float(\"lr_critic\", 1e-5, 1e-2, log = True)\n",
    "#     lr_actor = trial.suggest_float(\"lr_actor\", 1e-5, 1e-2, log = True)\n",
    "\n",
    "#     model = A2C(HyperParam(\n",
    "#         lr_critic = lr_critic,\n",
    "#         lr_actor = lr_actor,\n",
    "#         gamma = 0.99,\n",
    "#         hidden_dim = 128\n",
    "#     ))\n",
    "\n",
    "#     teacher = RL_Teacher(model, \"CartPole-v1_A2C_param_search\", f\"lrc_{lr_critic:.2e}_lra_{lr_actor:.2e}\", id = \"CartPole-v1\", render_mode = \"rgb_array\")\n",
    "#     avg_return = teacher.train(\n",
    "#         episode = 1200, is_log = False, \n",
    "#         last_episode_return = 300, \n",
    "#         is_fix_seed = True\n",
    "#     )\n",
    "#     return teacher.test(\n",
    "#         is_log_vedio = True, \n",
    "#         vedio_record_gap = 6\n",
    "#     ) + avg_return * 0.1\n",
    "\n",
    "# study = optuna.create_study(\n",
    "#     direction = \"maximize\", \n",
    "#     study_name = f\"CartPole-v1_A2C\", \n",
    "#     storage = \"sqlite:///optuna_study/CartPole-v1_A2C.db\", \n",
    "#     load_if_exists = True\n",
    "# )\n",
    "# study.optimize(target, 25)\n",
    "# print(study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
